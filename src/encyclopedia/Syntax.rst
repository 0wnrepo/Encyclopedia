
================================================================================
Syntax
================================================================================

Syntax is the study of the principles and processes by which sentences are
constructed in particular languages. (Arrangement of words)

The basic unit of interest is the sentence which minimally consists of an independent clause.

Kinds
=====

1. Transformation Grammar

Transformation Grammar
----------------------

A transformational grammar is a generative grammar that has been developed in the Chomskyan tradition of phase structure grammar.

# History

In 1956, Chomsky published "Three Models for the Description of Language" and introduced transformation grammar.

# Standard Theory

The Standard Theory (1957) corresponds to the original model of generative grammar laid out in Chomsky's 'Aspects of the theory of syntax'.

Linguists working in this view see a sentence as not merely a string of words, but rather a derivation tree. Phrase structure trees are not sufficient though, and require transformational grammar.

## Deep Structure & Surface Structure

In 1957, Chomsky published Syntactic Structures, in which he developed the idea that sentences have two levels of representation: a deep structure and a surface structure.

The deep structure of a linguist expression is a theoretical construct that represents the core semantics relations of a sentence. The deep structure is mapped onto to the surface structure via transformations.


Transformations had been proposed prior to the development of deep structure as a means of increasing the mathematical and descriptive power of context-free grammars.

Chomsky's advisor, Zellig Harris, took transformations to be relations between sentences.

Deep structures can unify similar structures that have similar meanings. For example, the sentences "Pat loves Chris" and "Chris is loved by Pat" means roughly the same thing and use similar words. To account for this similarity, some linguists (e.g. Chomsky) have to tried to account for this similarity by posting that these two sentences are distinct surface forms that derive from a common 'deep structure'.

Chomsky developed a formal theory of grammar where transformations maniulated not only the surface strings, but the parse tree associaed to them.

Chomsky noted that by dividing deep structures from surfaces structures, one could understand "slip of the tongue" moments (when someone say something one did not instend) as instances where deep structures do not translate into intended surface structure.

The deep structure concept caught on in unrelated fields (e.g architecture, music, politics) to express similar concepts.

---

Chomsky believes there are considerable similarities between language's deep structures. Chomsky has argued that many of the properties of a generative grammar arise from an "innate" universal grammar.

# Syntactic Sugar

> Syntactic Sugar is a code transformation which preserves semantics but eases use through clarification of intent. [6]

I wonder if this has something to do with ease of use. Would people use itertools more if everything inside was a builtin?

----

# Chomsky Hierarchy 

The Chomsky hierarchy is a containment hierarchy of classes of formal grammars introduced by Noam Chomsky in 1956.

- This is a containment hierarchy so the smaller boxes are contained in the larger boxes.

Chomsky hierarchy from most powerful to least powerful:

0. Recursively enumerable languages
1. Context-sensitive languages
2. Context-free languages
3. Regular languages

## Recursively Enumerable language

Recursively enumerable languages can be recognized by a Turing machine.

## Context-Sensitive language

Context-sensitive languages can be recognized by a linear-bounded non-deterministic Turing Machine.

## Context-free language (Phrase structure language)

A context-free language is a language generated by a context-free grammar. A context-free grammar is a formal grammar in which every production rule is of the form `V -> w` where `V` is a single nonterminal symbol, and `w` is a string of terminals or nonterminals.

Four components:

1. A set of terminal symbols, sometimes referred to as "tokens".
2. A set of nonterminals, sometimes called "syntactic variables".
3. A set of productions, where each production consists of a nonterminal, called the head or left side of the production, an arrow, and a sequence of terminals and/or nonterminals, called the body or right side of the production.
4. A designation of one of the nonterminals as the start symbol.

In computer science, a popular notation for context-free grammars is Backus-Naur Form.

CFGs can be recognized by non-deterministic pushdown automatons.

## Regular Languages

CFGs can be recognized by a finite state automaton.

