#!/usr/bin/env python
import logging
import os
import sys
import unicodedata

from whoosh.fields import Schema, ID, KEYWORD, STORED, TEXT
from whoosh.index import create_in, exists_in, open_dir
from whoosh.qparser import MultifieldParser

INDEX_PATH = '.index'
SCHEMA = Schema(
    content=TEXT(stored=True),
    tags=KEYWORD,
    title=ID(unique=True, stored=True),
    time=STORED,
)
SRC = "src"


class Document(object):
    def __init__(self, title, time, tags=None):
        self._title = title
        self.time = time
        self.tags = tags or []

    @property
    def title(self):
        return unicode(self._title)

    def _decode(self, text, encoding="UTF-8"):
        """
        Encode a Unicode string as ascii, ignoring any errors.
        """
        unistr = text.decode(encoding)
        form = unicodedata.normalize('NFKD', unistr)
        return form.encode('ascii', 'ignore')

    @property
    def content(self):
        with open(self.title, 'rU') as f:
            return unicode(self._decode(f.read()))


def get_or_create_index(path, schema, src):
    """Get or create an Index."""
    if not os.path.exists(path):
        os.mkdir(path)
    index = open_dir(path) if exists_in(path) else create_in(path, schema)
    indexed_titles = set(field['title'] for field in gen_indexed_fields(index))
    update_index(index.writer(), indexed_titles, gen_documents(src))
    return index


def gen_documents(src):
    for dirpath, _, filenames in os.walk(src):
        for filename in filenames:
            logging.debug("found: %s." % filename)
            if not filename.startswith("."):
                filepath = os.path.join(dirpath, filename)
                modtime = os.path.getmtime(filepath)
                yield Document(title=filepath, time=modtime)


def gen_indexed_fields(index):
    with index.searcher() as searcher:
        for field in searcher.all_stored_fields():
            yield field


def update_index(writer, indexed_titles, documents):
    for document in documents:
        if document.title not in indexed_titles:
            writer.add_document(title=document.title, content=document.content,
                                time=document.time)
        elif os.path.getmtime(document.title) > document.time:
            writer.delete_by_term('title', document.title)
            writer.add_document(title=document.title, content=document.content,
                                time=document.time)

    for indexed_title in indexed_titles:
        if not os.path.exists(indexed_title):
            writer.delete_by_term('title', indexed_title['title'])
    writer.commit()


def gen_results(index, q):
    with index.searcher(closereader=False) as searcher:
        results = searcher.search(q)
        for result in results:
            yield result


def search(index, querystring):
    q = MultifieldParser(["title", "content"], index.schema).parse(querystring)
    return gen_results(index, q)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    index = get_or_create_index(INDEX_PATH, SCHEMA, SRC)
    querystring = " ".join(sys.argv[1:])
    results = list(search(index, querystring))
    print "Found %s results:\n" % len(results)
    for result in results:
        print result["title"]
